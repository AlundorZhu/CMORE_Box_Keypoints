{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7df88fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "\n",
    "def generate_train_frames_and_labels(vidPath, label_txt_path, save_frame_path, save_label_path):\n",
    "    if not os.path.exists(label_txt_path):\n",
    "        return\n",
    "\n",
    "    os.makedirs(save_frame_path, exist_ok=True)\n",
    "    os.makedirs(save_label_path, exist_ok=True)\n",
    "                   \n",
    "    fileName = vidPath.split('/')[-1]\n",
    "    fileName = fileName.split('.')[0]\n",
    "    \n",
    "    cap = cv.VideoCapture(vidPath)\n",
    "    with open(label_txt_path, 'r') as f:\n",
    "            label_data = f.read()\n",
    "    while cap.isOpened():\n",
    "        frame_idx = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_path = os.path.join(save_frame_path, f\"{fileName}_frame_{int(frame_idx):06d}.png\")\n",
    "        cv.imwrite(frame_path, frame)\n",
    "                                                                                                                        \n",
    "        label_path = os.path.join(save_label_path, f\"{fileName}_frame_{int(frame_idx):06d}.txt\")\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(label_data)\n",
    "            \n",
    "\n",
    "generate_train_frames_and_labels(\n",
    "    vidPath='./IMG_1156.mov',\n",
    "    label_txt_path='./IMG_1156.txt',\n",
    "    save_frame_path='data/train/images',\n",
    "    save_label_path='data/train/labels'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d82b0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_yolo_label(label_line: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Parse a single YOLO pose label line\n",
    "    \n",
    "    Args:\n",
    "        label_line: String like \"0 0.538 0.468 0.780 0.643 0.148 0.639 2 ...\"\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - class_id: int\n",
    "            - bbox: np.array shape (4,) [x_center, y_center, width, height]\n",
    "            - keypoints_xy: np.array shape (10, 2) [x, y coordinates]\n",
    "            - visibility: np.array shape (10,) [visibility flags]\n",
    "    \"\"\"\n",
    "    values = label_line.strip().split()\n",
    "    values = [float(v) for v in values]\n",
    "    \n",
    "    class_id = int(values[0])\n",
    "    bbox = np.array(values[1:5])\n",
    "    \n",
    "    # Keypoints: groups of 3 (x, y, visibility)\n",
    "    kpt_data = np.array(values[5:]).reshape(-1, 3)\n",
    "    keypoints_xy = kpt_data[:, :2]  # Just x, y\n",
    "    visibility = kpt_data[:, 2]      # Visibility flags\n",
    "    \n",
    "    return {\n",
    "        'class_id': class_id,\n",
    "        'bbox': bbox,\n",
    "        'keypoints_xy': keypoints_xy,\n",
    "        'visibility': visibility\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_yolo_label_file(label_path: str) -> Dict:\n",
    "    \"\"\"Parse label from a .txt file\"\"\"\n",
    "    with open(label_path, 'r') as f:\n",
    "        line = f.read().strip()\n",
    "    return parse_yolo_label(line)\n",
    "\n",
    "\n",
    "def get_yolo_predictions(model, image_path: str, normalize: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Run YOLO inference and extract keypoints\n",
    "    \n",
    "    Args:\n",
    "        model: YOLO model instance\n",
    "        image_path: Path to image\n",
    "        normalize: If True, normalize keypoints to [0, 1] range\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - keypoints_xy: np.array shape (10, 2)\n",
    "            - confidence: float (detection confidence)\n",
    "    \"\"\"\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    results = model.predict(image_path, show=True)\n",
    "    \n",
    "    \n",
    "    image = cv.imread(str(image_path))\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    # print(f\"Image size: width={img_width}, height={img_height}\")\n",
    "    \n",
    "    # Check if any detections\n",
    "    if len(results[0].keypoints.xy) == 0:\n",
    "        # No detection - return zeros\n",
    "        return {\n",
    "            'keypoints_xy': np.zeros((10, 2)),\n",
    "            'confidence': 0.0\n",
    "        }\n",
    "    \n",
    "    # Get first detection (assuming single box in image)\n",
    "    pred_keypoints = results[0].keypoints.xy[0].cpu().numpy()\n",
    "    \n",
    "    if normalize:\n",
    "        # print(\"Normalizing predicted keypoints\")\n",
    "        # print(f\"Predicted keypoints before normalization: {pred_keypoints}\")\n",
    "        pred_keypoints_normalized = pred_keypoints.copy()\n",
    "        pred_keypoints_normalized[:, 0] = pred_keypoints_normalized[:, 0] / img_width   # Normalize x\n",
    "        pred_keypoints_normalized[:, 1] = pred_keypoints_normalized[:, 1] / img_height  # Normalize y\n",
    "        # print(f\"Predicted keypoints after normalization: {pred_keypoints_normalized}\")\n",
    "    else:\n",
    "        pred_keypoints_normalized = pred_keypoints\n",
    "    \n",
    "    # Get detection confidence if available\n",
    "    confidence = float(results[0].boxes.conf[0]) if len(results[0].boxes.conf) > 0 else 1.0\n",
    "    \n",
    "    return {\n",
    "        'keypoints_xy': pred_keypoints_normalized,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "\n",
    "def calculate_euclidean_distance(pred: np.ndarray, gt: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance between predicted and ground truth keypoints\n",
    "    \n",
    "    Args:\n",
    "        pred: shape (K, 2) - K keypoints, (x, y) coordinates\n",
    "        gt: shape (K, 2)\n",
    "    \n",
    "    Returns:\n",
    "        distances: shape (K,) - distance for each keypoint\n",
    "    \"\"\"\n",
    "    diff = pred - gt\n",
    "    distances = np.sqrt(np.sum(diff ** 2, axis=1))\n",
    "    return distances\n",
    "\n",
    "def calculate_mse_single(pred: np.ndarray, gt: np.ndarray, \n",
    "                        visibility: np.ndarray = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate MSE (Mean Squared Error) for a single image\n",
    "    \n",
    "    Args:\n",
    "        pred: shape (K, 2) - predicted keypoints\n",
    "        gt: shape (K, 2) - ground truth keypoints\n",
    "        visibility: shape (K,) - visibility flags (optional)\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - mse_overall: float (average MSE across all keypoints)\n",
    "            - mse_per_keypoint: np.array shape (K,)\n",
    "    \"\"\"\n",
    "    squared_diff = (pred - gt) ** 2\n",
    "    \n",
    "    if visibility is not None:\n",
    "        # Only compute MSE for visible keypoints (visibility == 2)\n",
    "        visible_mask = (visibility == 2)\n",
    "        \n",
    "        if not np.any(visible_mask):\n",
    "            # No visible keypoints\n",
    "            return {\n",
    "                'mse_overall': float('inf'),\n",
    "                'mse_per_keypoint': np.full(len(pred), float('inf'))\n",
    "            }\n",
    "        \n",
    "        # MSE per keypoint (x and y averaged)\n",
    "        mse_per_kpt = np.mean(squared_diff, axis=1)\n",
    "        mse_per_kpt = np.where(visible_mask, mse_per_kpt, np.nan)\n",
    "        \n",
    "        # Overall MSE (only visible)\n",
    "        mse_overall = np.nanmean(mse_per_kpt)\n",
    "    else:\n",
    "        mse_per_kpt = np.mean(squared_diff, axis=1)\n",
    "        mse_overall = np.mean(mse_per_kpt)\n",
    "    \n",
    "    return {\n",
    "        'mse_overall': float(mse_overall),\n",
    "        'mse_per_keypoint': mse_per_kpt\n",
    "    }\n",
    "\n",
    "def calculate_mae_single(pred: np.ndarray, gt: np.ndarray,\n",
    "                        visibility: np.ndarray = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate MAE (Mean Absolute Error) for a single image\n",
    "    \n",
    "    Args:\n",
    "        pred: shape (K, 2)\n",
    "        gt: shape (K, 2)\n",
    "        visibility: shape (K,)\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - mae_overall: float\n",
    "            - mae_per_keypoint: np.array shape (K,)\n",
    "    \"\"\"\n",
    "    abs_diff = np.abs(pred - gt)\n",
    "    \n",
    "    if visibility is not None:\n",
    "        visible_mask = (visibility == 2)\n",
    "        \n",
    "        if not np.any(visible_mask):\n",
    "            return {\n",
    "                'mae_overall': float('inf'),\n",
    "                'mae_per_keypoint': np.full(len(pred), float('inf'))\n",
    "            }\n",
    "        \n",
    "        mae_per_kpt = np.mean(abs_diff, axis=1)\n",
    "        mae_per_kpt = np.where(visible_mask, mae_per_kpt, np.nan)\n",
    "        mae_overall = np.nanmean(mae_per_kpt)\n",
    "    else:\n",
    "        mae_per_kpt = np.mean(abs_diff, axis=1)\n",
    "        mae_overall = np.mean(mae_per_kpt)\n",
    "    \n",
    "    return {\n",
    "        'mae_overall': float(mae_overall),\n",
    "        'mae_per_keypoint': mae_per_kpt\n",
    "    }\n",
    "    \n",
    "def calculate_pck_single(pred: np.ndarray, gt: np.ndarray, \n",
    "                        threshold: float = 0.05) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate PCK (Percentage of Correct Keypoints) for a single image\n",
    "    \n",
    "    Args:\n",
    "        pred: shape (K, 2)\n",
    "        gt: shape (K, 2)\n",
    "        threshold: distance threshold (normalized, e.g., 0.05 = 5% of image)\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "            - pck: float (percentage of correct keypoints, 0-1)\n",
    "            - correct_per_keypoint: np.array shape (K,) - bool array\n",
    "    \n",
    "    Interpretation:\n",
    "        PCK@0.05 = 0.95 means 95% of keypoints within 5% of image size    \n",
    "    \"\"\"\n",
    "    distances = calculate_euclidean_distance(pred, gt)\n",
    "    correct = distances < threshold\n",
    "    pck = np.mean(correct)\n",
    "    \n",
    "    return {\n",
    "        'pck': float(pck),\n",
    "        'correct_per_keypoint': correct\n",
    "    }\n",
    "\n",
    "def evaluate_single_frame(pred_keypoints: np.ndarray, \n",
    "                               gt_keypoints: np.ndarray,\n",
    "                               visibility: np.ndarray = None,\n",
    "                               thresholds: list = [0.02, 0.05, 0.10]) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate ALL metrics for a single frame\n",
    "    \n",
    "    Args:\n",
    "        pred_keypoints: shape (K, 2) - predicted keypoints\n",
    "        gt_keypoints: shape (K, 2) - ground truth keypoints\n",
    "        visibility: shape (K,) - visibility flags\n",
    "        thresholds: list of PCK thresholds to evaluate\n",
    "    \n",
    "    Returns:\n",
    "        dict with all metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    # MSE\n",
    "    mse_result = calculate_mse_single(pred_keypoints, gt_keypoints, visibility)\n",
    "    metrics['mse_overall'] = mse_result['mse_overall']\n",
    "    metrics['mse_per_keypoint'] = mse_result['mse_per_keypoint']\n",
    "    \n",
    "    # MAE\n",
    "    mae_result = calculate_mae_single(pred_keypoints, gt_keypoints, visibility)\n",
    "    metrics['mae_overall'] = mae_result['mae_overall']\n",
    "    metrics['mae_per_keypoint'] = mae_result['mae_per_keypoint']\n",
    "    \n",
    "    # PCK at multiple thresholds\n",
    "    for thresh in thresholds:\n",
    "        pck_result = calculate_pck_single(pred_keypoints, gt_keypoints, thresh)\n",
    "        metrics[f'pck_{thresh}'] = pck_result['pck']\n",
    "        metrics[f'pck_{thresh}_per_keypoint'] = pck_result['correct_per_keypoint']\n",
    "    \n",
    "    # Per-keypoint Euclidean distances (useful for analysis)\n",
    "    metrics['distances'] = calculate_euclidean_distance(pred_keypoints, gt_keypoints)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c98edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SINGLE IMAGE EVALUATION EXAMPLE\n",
      "======================================================================\n",
      "\n",
      "Loaded model: .//best.pt\n",
      "Image: data/train/images/IMG_1156_frame_000001.png\n",
      "Label: data/train/labels/IMG_1156_frame_000001.txt\n",
      "\n",
      "Ground Truth Keypoints:\n",
      "{'class_id': 0, 'bbox': array([    0.48884,     0.43644,     0.90866,     0.67783]), 'keypoints_xy': array([[   0.034516,     0.57294],\n",
      "       [   0.064146,     0.77364],\n",
      "       [    0.49159,     0.55046],\n",
      "       [    0.49159,     0.77469],\n",
      "       [    0.94317,     0.57562],\n",
      "       [    0.91748,     0.77536],\n",
      "       [    0.49115,    0.097528],\n",
      "       [    0.48891,     0.28708],\n",
      "       [    0.17536,     0.28119],\n",
      "       [    0.80877,      0.2842]]), 'visibility': array([          2,           2,           2,           2,           2,           2,           2,           2,           2,           2])}\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000001.png: 288x512 1 box, 12.3ms\n",
      "Speed: 0.7ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Image size: width=1920, height=1080\n",
      "Normalizing predicted keypoints\n",
      "pred_data: {'keypoints_xy': array([[   0.036935,     0.57035],\n",
      "       [   0.056353,     0.78084],\n",
      "       [    0.48902,     0.53869],\n",
      "       [    0.49609,      0.7691],\n",
      "       [     0.9398,     0.56567],\n",
      "       [    0.94053,     0.77494],\n",
      "       [    0.49529,    0.086204],\n",
      "       [    0.48078,     0.26635],\n",
      "       [     0.1669,     0.29803],\n",
      "       [    0.84586,     0.28604]], dtype=float32), 'confidence': 0.9663413166999817}\n",
      "\n",
      "Overall Metrics:\n",
      "  MSE: 0.000167\n",
      "  MAE: 0.009490\n",
      "  PCK@0.02: 0.7000\n",
      "  PCK@0.05: 1.0000\n",
      "  PCK@0.10: 1.0000\n",
      "\n",
      "Per-Keypoint Analysis:\n",
      "  Keypoint     Distance     MSE          Correct@0.05\n",
      "  --------------------------------------------------\n",
      "  FrontTopL    0.003546     0.000006     Yes\n",
      "  FrontBotL    0.010608     0.000056     Yes\n",
      "  FrontTopM    0.012054     0.000073     Yes\n",
      "  FrontBotM    0.007179     0.000026     Yes\n",
      "  FrontTopR    0.010508     0.000055     Yes\n",
      "  FrontBotR    0.023058     0.000266     Yes\n",
      "  BackDivTop   0.012059     0.000073     Yes\n",
      "  FrontDivTop  0.022273     0.000248     Yes\n",
      "  BackTopL     0.018840     0.000177     Yes\n",
      "  BackTopR     0.037129     0.000689     Yes\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"SINGLE IMAGE EVALUATION EXAMPLE\")\n",
    "\n",
    "# 1. Load model\n",
    "model_path = './/best.pt'\n",
    "model = YOLO(model_path)\n",
    "print(f\"\\nLoaded model: {model_path}\")\n",
    "\n",
    "# 2. Load image and label\n",
    "image_path = 'data/train/images/IMG_1156_frame_000001.png'\n",
    "label_path = 'data/train/labels/IMG_1156_frame_000001.txt'\n",
    "\n",
    "print(f\"Image: {image_path}\")\n",
    "print(f\"Label: {label_path}\")\n",
    "\n",
    "# 3. Parse ground truth\n",
    "gt_data = parse_yolo_label_file(label_path)\n",
    "\n",
    "print(\"\\nGround Truth Keypoints:\")\n",
    "print(gt_data)\n",
    "gt_keypoints = gt_data['keypoints_xy']\n",
    "visibility = gt_data['visibility']\n",
    "\n",
    "# 4. Get predictions\n",
    "pred_data = get_yolo_predictions(model, image_path, normalize=True)\n",
    "\n",
    "print(f\"pred_data: {pred_data}\")\n",
    "pred_keypoints = pred_data['keypoints_xy']\n",
    "confidence = pred_data['confidence']\n",
    "\n",
    "# 5. Calculate metrics\n",
    "metrics = evaluate_single_frame(\n",
    "    pred_keypoints, \n",
    "    gt_keypoints, \n",
    "    visibility,\n",
    "    thresholds=[0.02, 0.05, 0.10]\n",
    ")\n",
    "\n",
    "# 6. Display results\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"  MSE: {metrics['mse_overall']:.6f}\")\n",
    "print(f\"  MAE: {metrics['mae_overall']:.6f}\")\n",
    "print(f\"  PCK@0.02: {metrics['pck_0.02']:.4f}\")\n",
    "print(f\"  PCK@0.05: {metrics['pck_0.05']:.4f}\")\n",
    "print(f\"  PCK@0.10: {metrics['pck_0.1']:.4f}\")\n",
    "\n",
    "print(f\"\\nPer-Keypoint Analysis:\")\n",
    "print(f\"  {'Keypoint':<12} {'Distance':<12} {'MSE':<12} {'Correct@0.05'}\")\n",
    "print(f\"  {'-'*50}\")\n",
    "\n",
    "keypoint_names = [\n",
    "    'FrontTopL', 'FrontBotL', 'FrontTopM', 'FrontBotM',\n",
    "    'FrontTopR', 'FrontBotR', 'BackDivTop', 'FrontDivTop',\n",
    "    'BackTopL', 'BackTopR'\n",
    "]\n",
    "\n",
    "for i, name in enumerate(keypoint_names):\n",
    "    dist = metrics['distances'][i]\n",
    "    mse = metrics['mse_per_keypoint'][i]\n",
    "    correct = 'Yes' if metrics['pck_0.05_per_keypoint'][i] else 'No'\n",
    "    print(f\"  {name:<12} {dist:<12.6f} {mse:<12.6f} {correct}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ec5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATE ALL TEST IMAGES\n",
      "Loading model from: .//best.pt\n",
      "Found 50 test images.\n",
      "Evaluating 50 images with labels.\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000000.png: 288x512 1 box, 11.7ms\n",
      "Speed: 0.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000001.png: 288x512 1 box, 12.0ms\n",
      "Speed: 0.7ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000002.png: 288x512 1 box, 12.0ms\n",
      "Speed: 0.7ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000003.png: 288x512 1 box, 12.2ms\n",
      "Speed: 0.7ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000004.png: 288x512 1 box, 11.7ms\n",
      "Speed: 0.8ms preprocess, 11.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000005.png: 288x512 1 box, 19.7ms\n",
      "Speed: 0.8ms preprocess, 19.7ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000006.png: 288x512 1 box, 21.8ms\n",
      "Speed: 1.1ms preprocess, 21.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000007.png: 288x512 1 box, 22.8ms\n",
      "Speed: 0.8ms preprocess, 22.8ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000008.png: 288x512 1 box, 24.6ms\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000009.png: 288x512 1 box, 27.0ms\n",
      "Speed: 0.8ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000010.png: 288x512 1 box, 29.0ms\n",
      "Speed: 0.9ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000011.png: 288x512 1 box, 31.0ms\n",
      "Speed: 0.9ms preprocess, 31.0ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000012.png: 288x512 1 box, 33.1ms\n",
      "Speed: 0.9ms preprocess, 33.1ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000013.png: 288x512 1 box, 101.7ms\n",
      "Speed: 0.9ms preprocess, 101.7ms inference, 2.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000014.png: 288x512 1 box, 90.5ms\n",
      "Speed: 1.0ms preprocess, 90.5ms inference, 3.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000015.png: 288x512 1 box, 70.8ms\n",
      "Speed: 2.6ms preprocess, 70.8ms inference, 2.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000016.png: 288x512 1 box, 10.9ms\n",
      "Speed: 0.7ms preprocess, 10.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000017.png: 288x512 1 box, 10.5ms\n",
      "Speed: 0.7ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000018.png: 288x512 1 box, 11.0ms\n",
      "Speed: 0.7ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000019.png: 288x512 1 box, 10.7ms\n",
      "Speed: 0.8ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000020.png: 288x512 1 box, 19.9ms\n",
      "Speed: 0.8ms preprocess, 19.9ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000021.png: 288x512 1 box, 20.8ms\n",
      "Speed: 0.8ms preprocess, 20.8ms inference, 2.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000022.png: 288x512 1 box, 22.6ms\n",
      "Speed: 0.8ms preprocess, 22.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000023.png: 288x512 1 box, 25.0ms\n",
      "Speed: 0.8ms preprocess, 25.0ms inference, 1.9ms postprocess per image at shape (1, 3, 288, 512)\n",
      "  Progress: 25/50\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000024.png: 288x512 1 box, 27.9ms\n",
      "Speed: 0.8ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000025.png: 288x512 1 box, 29.0ms\n",
      "Speed: 0.8ms preprocess, 29.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000026.png: 288x512 1 box, 32.1ms\n",
      "Speed: 0.8ms preprocess, 32.1ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000027.png: 288x512 1 box, 34.1ms\n",
      "Speed: 0.9ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000028.png: 288x512 1 box, 36.9ms\n",
      "Speed: 0.8ms preprocess, 36.9ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000029.png: 288x512 1 box, 38.8ms\n",
      "Speed: 0.9ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000030.png: 288x512 1 box, 40.1ms\n",
      "Speed: 0.8ms preprocess, 40.1ms inference, 2.2ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000031.png: 288x512 1 box, 44.1ms\n",
      "Speed: 0.9ms preprocess, 44.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000032.png: 288x512 1 box, 45.4ms\n",
      "Speed: 0.9ms preprocess, 45.4ms inference, 2.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000033.png: 288x512 1 box, 121.8ms\n",
      "Speed: 1.7ms preprocess, 121.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000034.png: 288x512 1 box, 95.1ms\n",
      "Speed: 0.9ms preprocess, 95.1ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000035.png: 288x512 1 box, 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 2.7ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000036.png: 288x512 1 box, 10.2ms\n",
      "Speed: 0.7ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000037.png: 288x512 1 box, 11.0ms\n",
      "Speed: 0.8ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000038.png: 288x512 1 box, 10.6ms\n",
      "Speed: 0.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000039.png: 288x512 1 box, 11.1ms\n",
      "Speed: 0.8ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000040.png: 288x512 1 box, 20.3ms\n",
      "Speed: 0.7ms preprocess, 20.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000041.png: 288x512 1 box, 20.8ms\n",
      "Speed: 1.0ms preprocess, 20.8ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000042.png: 288x512 1 box, 22.8ms\n",
      "Speed: 0.8ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000043.png: 288x512 1 box, 25.2ms\n",
      "Speed: 0.8ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000044.png: 288x512 1 box, 26.4ms\n",
      "Speed: 0.8ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000045.png: 288x512 1 box, 29.0ms\n",
      "Speed: 0.8ms preprocess, 29.0ms inference, 1.3ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000046.png: 288x512 1 box, 32.3ms\n",
      "Speed: 0.8ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000047.png: 288x512 1 box, 33.8ms\n",
      "Speed: 0.8ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 288, 512)\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000048.png: 288x512 1 box, 36.0ms\n",
      "Speed: 0.9ms preprocess, 36.0ms inference, 1.4ms postprocess per image at shape (1, 3, 288, 512)\n",
      "  Progress: 50/50\n",
      "\n",
      "image 1/1 d:\\cs_projects\\CMORE_Box_Keypoints\\data\\train\\images\\IMG_1156_frame_000049.png: 288x512 1 box, 109.3ms\n",
      "Speed: 0.9ms preprocess, 109.3ms inference, 3.1ms postprocess per image at shape (1, 3, 288, 512)\n",
      "Evaluated 50 images.\n",
      "\n",
      "Overall Dataset Metrics:\n",
      "Total Images Evaluated: 50\n",
      "Failed Images: 0\n",
      "  MSE: 0.000165\n",
      "  MAE: 0.009392\n",
      "  PCK@0.02: 0.7020\n",
      "  PCK@0.05: 1.0000\n",
      "  PCK@0.10: 1.0000\n",
      "\n",
      "Average Per-Keypoint Metrics:\n",
      "  Keypoint     Avg Distance    Avg MSE         PCK@0.05\n",
      "  ------------------------------------------------------------\n",
      "  FrontTopL    0.003339        0.000006        1.0000\n",
      "  FrontBotL    0.010794        0.000058        1.0000\n",
      "  FrontTopM    0.011896        0.000071        1.0000\n",
      "  FrontBotM    0.007027        0.000025        1.0000\n",
      "  FrontTopR    0.009677        0.000047        1.0000\n",
      "  FrontBotR    0.023183        0.000269        1.0000\n",
      "  BackDivTop   0.012837        0.000083        1.0000\n",
      "  FrontDivTop  0.022051        0.000243        1.0000\n",
      "  BackTopL     0.018228        0.000167        1.0000\n",
      "  BackTopR     0.036939        0.000682        1.0000\n",
      "\n",
      "Saved evaluation results to: evaluation_results_20251120_233631.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mse_overall': 0.00016508917068535245,\n",
       " 'mae_overall': 0.00939194630614042,\n",
       " 'pck_0.02': 0.7020000000000002,\n",
       " 'pck_0.05': 1.0,\n",
       " 'pck_0.1': 1.0,\n",
       " 'avg_distances_per_keypoint': [0.003339289216485081,\n",
       "  0.010793506824754858,\n",
       "  0.011895563066887868,\n",
       "  0.007026570620736547,\n",
       "  0.009676984471908788,\n",
       "  0.02318293226973189,\n",
       "  0.012837331289792664,\n",
       "  0.022050583448786833,\n",
       "  0.018228111477448093,\n",
       "  0.036939205618616015],\n",
       " 'avg_mse_per_keypoint': [5.616007876053586e-06,\n",
       "  5.828013948180556e-05,\n",
       "  7.081844355377459e-05,\n",
       "  2.470319262406303e-05,\n",
       "  4.734053116351326e-05,\n",
       "  0.00026880501941945877,\n",
       "  8.294876261324715e-05,\n",
       "  0.00024333805431136417,\n",
       "  0.00016667773906525632,\n",
       "  0.0006823638167449878],\n",
       " 'avg_pck_per_keypoint': {'pck_0.02': [1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.02,\n",
       "   1.0,\n",
       "   0.0],\n",
       "  'pck_0.05': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "  'pck_0.1': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]},\n",
       " 'num_images': 50,\n",
       " 'num_failed': 0,\n",
       " 'model_path': './/best.pt',\n",
       " 'test_images_dir': 'data\\\\train\\\\images',\n",
       " 'test_labels_dir': 'data\\\\train\\\\labels',\n",
       " 'timestamp': '2025-11-20T23:36:31.639520'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import json\n",
    "from datetime import datetime\n",
    "    \n",
    "print(\"EVALUATE ALL TEST IMAGES\")\n",
    "\n",
    "def evaluate_dataset(model_path: str, test_images_dir: str, test_labels_dir: str,\n",
    "                    save_results: bool = True, output_path: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate model on entire test dataset\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to YOLO model (.pt file)\n",
    "        test_images_dir: Directory with test images\n",
    "        test_labels_dir: Directory with test labels (.txt files)\n",
    "        save_results: Whether to save results to JSON\n",
    "        output_path: Where to save results (optional)\n",
    "    \n",
    "    Returns:\n",
    "        dict with aggregated metrics across all images\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    test_images_dir = Path(test_images_dir)\n",
    "    test_labels_dir = Path(test_labels_dir)\n",
    "    \n",
    "    test_images = []\n",
    "    for img_file in test_images_dir.glob('*'):\n",
    "        test_images.append(img_file)\n",
    "    test_images = test_images[:50]\n",
    "    print(f\"Found {len(test_images)} test images.\")\n",
    "    \n",
    "    images_with_labels = []\n",
    "    for img_path in test_images:\n",
    "        label_path = test_labels_dir / (img_path.stem + '.txt')\n",
    "        if label_path.exists():\n",
    "            images_with_labels.append((img_path, label_path))\n",
    "        else:\n",
    "            print(f\"Warning: No label file for image {img_path.name}, skipping.\")\n",
    "            \n",
    "    print(f\"Evaluating {len(images_with_labels)} images with labels.\")\n",
    "    \n",
    "    test_images = images_with_labels\n",
    "    all_metrics = []\n",
    "    all_distances = []\n",
    "    all_mse_per_kpt = []\n",
    "    all_pck_per_kpt = {\n",
    "        'pck_0.02': [],\n",
    "        'pck_0.05': [],\n",
    "        'pck_0.1': []\n",
    "    }\n",
    "    \n",
    "    failed_images = []\n",
    "    \n",
    "    for idx, (img_path, label_path) in enumerate(test_images):\n",
    "        if (idx + 1) % 25 == 0:\n",
    "            print(f\"  Progress: {idx + 1}/{len(test_images)}\")\n",
    "                \n",
    "        try:\n",
    "            gt_data = parse_yolo_label_file(str(label_path))\n",
    "            \n",
    "            pred_data = get_yolo_predictions(model, str(img_path), normalize=True)\n",
    "            \n",
    "            metrics = evaluate_single_frame(\n",
    "                pred_data['keypoints_xy'],\n",
    "                gt_data['keypoints_xy'],\n",
    "                gt_data['visibility'],\n",
    "                thresholds=[0.02, 0.05, 0.10]\n",
    "            )\n",
    "            \n",
    "            all_metrics.append({\n",
    "                'image': img_path.name,\n",
    "                'mse': metrics['mse_overall'],\n",
    "                'mae': metrics['mae_overall'],\n",
    "                'pck_0.02': metrics.get('pck_0.02', 0.0),\n",
    "                'pck_0.05': metrics.get('pck_0.05', 0.0),\n",
    "                'pck_0.1': metrics.get('pck_0.1', 0.0),\n",
    "                'confidence': pred_data['confidence']\n",
    "            })\n",
    "            all_distances.append(metrics['distances'])\n",
    "            all_mse_per_kpt.append(metrics['mse_per_keypoint'])\n",
    "            \n",
    "            all_pck_per_kpt['pck_0.02'].append(metrics['pck_0.02_per_keypoint'])\n",
    "            all_pck_per_kpt['pck_0.05'].append(metrics['pck_0.05_per_keypoint'])\n",
    "            all_pck_per_kpt['pck_0.1'].append(metrics['pck_0.1_per_keypoint'])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  WARNING: Failed on {img_path.name}: {e}\")\n",
    "            failed_images.append(str(img_path.name))\n",
    "            \n",
    "    print(f\"Evaluated {len(all_metrics)} images.\")\n",
    "    \n",
    "    if failed_images:\n",
    "        print(f\"Failed on {len(failed_images)} images: {failed_images}\")\n",
    "            \n",
    "    # Aggregate overall metrics\n",
    "    all_distances = np.array(all_distances)\n",
    "    all_mse_per_kpt = np.array(all_mse_per_kpt)\n",
    "    \n",
    "    overall_metrics = {\n",
    "        'mse_overall': float(np.mean([m['mse'] for m in all_metrics])),\n",
    "        'mae_overall': float(np.mean([m['mae'] for m in all_metrics])),\n",
    "        'pck_0.02': float(np.mean([m['pck_0.02'] for m in all_metrics])),\n",
    "        'pck_0.05': float(np.mean([m['pck_0.05'] for m in all_metrics])),\n",
    "        'pck_0.1': float(np.mean([m['pck_0.1'] for m in all_metrics])),\n",
    "        'avg_distances_per_keypoint': np.mean(all_distances, axis=0).tolist(),\n",
    "        'avg_mse_per_keypoint': np.mean(all_mse_per_kpt, axis=0).tolist(),\n",
    "        'avg_pck_per_keypoint': {\n",
    "            'pck_0.02': np.mean(all_pck_per_kpt['pck_0.02'], axis=0).tolist(),\n",
    "            'pck_0.05': np.mean(all_pck_per_kpt['pck_0.05'], axis=0).tolist(),\n",
    "            'pck_0.1': np.mean(all_pck_per_kpt['pck_0.1'], axis=0).tolist(),\n",
    "        },\n",
    "        'num_images': len(all_metrics),\n",
    "        'num_failed': len(failed_images),\n",
    "        'model_path': str(model_path),\n",
    "        'test_images_dir': str(test_images_dir),\n",
    "        'test_labels_dir': str(test_labels_dir),\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "    }\n",
    "    \n",
    "    print(\"\\nOverall Dataset Metrics:\")\n",
    "    print(f\"Total Images Evaluated: {overall_metrics['num_images']}\")\n",
    "    print(f\"Failed Images: {overall_metrics['num_failed']}\")\n",
    "    print(f\"  MSE: {overall_metrics['mse_overall']:.6f}\")\n",
    "    print(f\"  MAE: {overall_metrics['mae_overall']:.6f}\")\n",
    "    print(f\"  PCK@0.02: {overall_metrics['pck_0.02']:.4f}\")\n",
    "    print(f\"  PCK@0.05: {overall_metrics['pck_0.05']:.4f}\")\n",
    "    print(f\"  PCK@0.10: {overall_metrics['pck_0.1']:.4f}\")\n",
    "    \n",
    "    print(\"\\nAverage Per-Keypoint Metrics:\")\n",
    "    keypoint_names = [\n",
    "        'FrontTopL', 'FrontBotL', 'FrontTopM', 'FrontBotM',\n",
    "        'FrontTopR', 'FrontBotR', 'BackDivTop', 'FrontDivTop',\n",
    "        'BackTopL', 'BackTopR'\n",
    "    ]\n",
    "    print(f\"  {'Keypoint':<12} {'Avg Distance':<15} {'Avg MSE':<15} {'PCK@0.05'}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "    for i, name in enumerate(keypoint_names):\n",
    "        avg_dist = overall_metrics['avg_distances_per_keypoint'][i]\n",
    "        avg_mse = overall_metrics['avg_mse_per_keypoint'][i]\n",
    "        pck_05 = overall_metrics['avg_pck_per_keypoint']['pck_0.05'][i]\n",
    "        print(f\"  {name:<12} {avg_dist:<15.6f} {avg_mse:<15.6f} {pck_05:.4f}\")\n",
    "        \n",
    "    # Save results to JSON\n",
    "    if save_results:\n",
    "        if output_path is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = f\"evaluation_results_{timestamp}.json\"\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(overall_metrics, f, indent=4)\n",
    "        \n",
    "        print(f\"\\nSaved evaluation results to: {output_path}\")\n",
    "        \n",
    "    return overall_metrics\n",
    "\n",
    "# Example usage:\n",
    "evaluate_dataset(\n",
    "    model_path='.//best.pt', # model is from https://github.com/AlundorZhu/CMORE/blob/24d8e02045004bb753b986f82fdf974e70d14637/playground/keypoints/runs/pose/train/weights/best.pt\n",
    "    test_images_dir='data/train/images',\n",
    "    test_labels_dir='data/train/labels',\n",
    "    save_results=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evs271_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
